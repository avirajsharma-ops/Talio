import { NextResponse } from 'next/server';
import { jwtVerify } from 'jose';
import connectDB from '@/lib/mongodb';
import User from '@/models/User';
import ScreenMonitorLog from '@/models/ScreenMonitorLog';
import OpenAI from 'openai';
import { getCurrentISTDate, formatISTDateTime, toISTString } from '@/lib/timezone';

const JWT_SECRET = new TextEncoder().encode(process.env.JWT_SECRET || 'your-secret-key');

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || process.env.NEXT_PUBLIC_OPENAI_API_KEY
});

export async function POST(request) {
  try {
    await connectDB();

    // Verify JWT token
    const authHeader = request.headers.get('authorization');
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return NextResponse.json(
        { error: 'Unauthorized - No token provided' },
        { status: 401 }
      );
    }

    const token = authHeader.split(' ')[1];
    let decoded;
    try {
      const { payload } = await jwtVerify(token, JWT_SECRET);
      decoded = payload;
    } catch (error) {
      return NextResponse.json(
        { error: 'Unauthorized - Invalid token' },
        { status: 401 }
      );
    }

    const user = await User.findById(decoded.userId).lean();
    if (!user || !user.employeeId) {
      return NextResponse.json(
        { error: 'User not found or not linked to employee' },
        { status: 404 }
      );
    }

    const body = await request.json();
    const { logId, screenshot, metadata } = body;

    if (!logId || !screenshot) {
      return NextResponse.json(
        { error: 'Log ID and screenshot are required' },
        { status: 400 }
      );
    }

    // Find the monitoring log
    const monitorLog = await ScreenMonitorLog.findById(logId);
    if (!monitorLog) {
      return NextResponse.json(
        { error: 'Monitoring log not found' },
        { status: 404 }
      );
    }

    // Verify the screenshot is from the correct employee
    if (monitorLog.targetEmployee.toString() !== user.employeeId.toString()) {
      return NextResponse.json(
        { error: 'Unauthorized - Screenshot must be from target employee' },
        { status: 403 }
      );
    }

    // Check screenshot size (limit to 5MB base64)
    const screenshotSize = screenshot.length;
    if (screenshotSize > 5 * 1024 * 1024) {
      return NextResponse.json(
        { error: 'Screenshot too large. Maximum 5MB' },
        { status: 400 }
      );
    }

    // Update log with screenshot
    monitorLog.screenshot = {
      data: screenshot,
      mimeType: 'image/png',
      size: screenshotSize,
      capturedAt: new Date()
    };
    monitorLog.metadata = metadata || {};
    monitorLog.status = 'captured';
    await monitorLog.save();

    // Analyze screenshot with OpenAI Vision
    try {
      const visionResponse = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: `You are MAYA, an AI assistant analyzing employee screen activity. Provide a professional, objective summary of what the employee is doing based on the screenshot. Include:
1. A brief summary of visible activity
2. Applications or websites visible
3. Type of work being performed
4. Productivity assessment (high/medium/low)
5. Any notable observations

Be factual and professional. Focus on work-related observations.`
          },
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Analyze this employee screen capture and provide a detailed activity summary. Employee: ${monitorLog.targetEmployeeName}, Department: ${monitorLog.targetDepartmentName || 'Unknown'}, Time: ${new Date().toLocaleString()}`
              },
              {
                type: 'image_url',
                image_url: {
                  url: screenshot.startsWith('data:') ? screenshot : `data:image/png;base64,${screenshot}`
                }
              }
            ]
          }
        ],
        max_tokens: 500,
        temperature: 0.3
      });

      const analysisText = visionResponse.choices[0]?.message?.content || 'Unable to analyze screenshot';

      // Parse the analysis to extract structured data
      const productivityMatch = analysisText.match(/productivity[:\s]+(\w+)/i);
      const productivityLevel = productivityMatch 
        ? productivityMatch[1].toLowerCase() 
        : 'unknown';

      // Update log with analysis
      monitorLog.analysis = {
        summary: analysisText,
        applications: extractApplications(analysisText),
        activity: extractActivity(analysisText),
        productivityLevel: ['high', 'medium', 'low'].includes(productivityLevel) 
          ? productivityLevel 
          : 'unknown',
        detectedContent: analysisText.substring(0, 500),
        aiResponse: analysisText
      };
      monitorLog.status = 'analyzed';
      await monitorLog.save();

      // Emit socket event to requester with analysis
      const io = global.io;
      if (io) {
        io.to(`user:${monitorLog.requestedBy}`).emit('maya:screen-analysis-complete', {
          logId: monitorLog._id.toString(),
          targetEmployee: monitorLog.targetEmployeeName,
          summary: analysisText.substring(0, 200) + '...',
          productivityLevel: monitorLog.analysis.productivityLevel,
          timestamp: new Date().toISOString()
        });
      }

      return NextResponse.json({
        success: true,
        message: 'Screenshot captured and analyzed',
        logId: monitorLog._id,
        analysis: {
          summary: analysisText.substring(0, 200) + '...',
          productivityLevel: monitorLog.analysis.productivityLevel
        }
      });

    } catch (visionError) {
      console.error('OpenAI Vision analysis error:', visionError);
      
      // Update log with error but keep screenshot
      monitorLog.status = 'failed';
      monitorLog.error = visionError.message;
      monitorLog.analysis = {
        summary: 'AI analysis failed',
        productivityLevel: 'unknown',
        aiResponse: `Error: ${visionError.message}`
      };
      await monitorLog.save();

      return NextResponse.json({
        success: false,
        message: 'Screenshot captured but analysis failed',
        logId: monitorLog._id,
        error: process.env.NODE_ENV === 'development' ? visionError.message : 'Analysis failed'
      }, { status: 500 });
    }

  } catch (error) {
    console.error('Screen capture error:', error);
    return NextResponse.json(
      { 
        error: 'Failed to process screen capture',
        message: process.env.NODE_ENV === 'development' ? error.message : 'Internal server error'
      },
      { status: 500 }
    );
  }
}

// Helper function to extract applications from analysis text
function extractApplications(text) {
  const apps = [];
  const commonApps = [
    'Chrome', 'Firefox', 'Safari', 'Edge', 'Slack', 'Teams', 
    'Zoom', 'Excel', 'Word', 'PowerPoint', 'VS Code', 'IntelliJ',
    'Photoshop', 'Figma', 'Jira', 'Trello', 'Gmail', 'Outlook'
  ];
  
  for (const app of commonApps) {
    if (text.toLowerCase().includes(app.toLowerCase())) {
      apps.push(app);
    }
  }
  
  return apps;
}

// Helper function to extract activity type from analysis
function extractActivity(text) {
  const activities = {
    'coding': ['code', 'programming', 'development', 'IDE', 'terminal'],
    'communication': ['email', 'chat', 'meeting', 'slack', 'teams'],
    'documentation': ['document', 'writing', 'word', 'docs', 'notes'],
    'browsing': ['browser', 'web', 'internet', 'browsing'],
    'design': ['design', 'figma', 'photoshop', 'sketch'],
    'analysis': ['spreadsheet', 'excel', 'data', 'analytics']
  };

  const textLower = text.toLowerCase();
  
  for (const [activity, keywords] of Object.entries(activities)) {
    if (keywords.some(keyword => textLower.includes(keyword))) {
      return activity;
    }
  }
  
  return 'general work';
}
